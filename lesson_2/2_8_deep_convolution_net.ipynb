{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"2_8_deep_convolution_net.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8cNl2QA_Rnv5"},"source":["# 準備"]},{"cell_type":"markdown","metadata":{"id":"YkwjN1jNVAYy"},"source":["## Googleドライブのマウント"]},{"cell_type":"code","metadata":{"id":"pvFXpiH3EVC1","outputId":"11fb8ba8-a693-45bb-a6d0-153f75d151b4","executionInfo":{"status":"ok","timestamp":1640565125410,"user_tz":-540,"elapsed":29052,"user":{"displayName":"富樫正尚","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11564743336490416698"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"3Ub7RYdeY6pK"},"source":["## sys.pathの設定"]},{"cell_type":"markdown","metadata":{"id":"oql7L19rEsWi"},"source":["以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"]},{"cell_type":"code","metadata":{"id":"7Ic2JzkvFX59","executionInfo":{"status":"ok","timestamp":1640565194682,"user_tz":-540,"elapsed":424,"user":{"displayName":"富樫正尚","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11564743336490416698"}}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/DNN_code')"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PAEQ-7jl-odi"},"source":["# deep convolution network"]},{"cell_type":"code","metadata":{"id":"B3j6DAkk-odk","executionInfo":{"status":"ok","timestamp":1640565199832,"user_tz":-540,"elapsed":3348,"user":{"displayName":"富樫正尚","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11564743336490416698"}}},"source":["import pickle\n","import numpy as np\n","from collections import OrderedDict\n","from common import layers\n","from data.mnist import load_mnist\n","import matplotlib.pyplot as plt\n","from common import optimizer\n","\n","class DeepConvNet:\n","    '''\n","    認識率99%以上の高精度なConvNet\n","\n","    conv - relu - conv- relu - pool -\n","    conv - relu - conv- relu - pool -\n","    conv - relu - conv- relu - pool -\n","    affine - relu - dropout - affine - dropout - softmax\n","    '''\n","    def __init__(self, input_dim=(1, 28, 28),\n","                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n","                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n","                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n","                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n","                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n","                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n","                 hidden_size=50, output_size=10):\n","        # 重みの初期化===========\n","        # 各層のニューロンひとつあたりが、前層のニューロンといくつのつながりがあるか\n","        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n","        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # Heの初期値\n","        \n","        self.params = {}\n","        pre_channel_num = input_dim[0]\n","        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n","            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n","            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n","            pre_channel_num = conv_param['filter_num']\n","        self.params['W7'] = wight_init_scales[6] * np.random.randn(pre_node_nums[6], hidden_size)\n","        print(self.params['W7'].shape)\n","        self.params['b7'] = np.zeros(hidden_size)\n","        self.params['W8'] = wight_init_scales[7] * np.random.randn(pre_node_nums[7], output_size)\n","        self.params['b8'] = np.zeros(output_size)\n","\n","        # レイヤの生成===========\n","        self.layers = []\n","        self.layers.append(layers.Convolution(self.params['W1'], self.params['b1'], \n","                           conv_param_1['stride'], conv_param_1['pad']))\n","        self.layers.append(layers.Relu())\n","        self.layers.append(layers.Convolution(self.params['W2'], self.params['b2'], \n","                           conv_param_2['stride'], conv_param_2['pad']))\n","        self.layers.append(layers.Relu())\n","        self.layers.append(layers.Pooling(pool_h=2, pool_w=2, stride=2))\n","        self.layers.append(layers.Convolution(self.params['W3'], self.params['b3'], \n","                           conv_param_3['stride'], conv_param_3['pad']))\n","        self.layers.append(layers.Relu())\n","        self.layers.append(layers.Convolution(self.params['W4'], self.params['b4'],\n","                           conv_param_4['stride'], conv_param_4['pad']))\n","        self.layers.append(layers.Relu())\n","        self.layers.append(layers.Pooling(pool_h=2, pool_w=2, stride=2))\n","        self.layers.append(layers.Convolution(self.params['W5'], self.params['b5'],\n","                           conv_param_5['stride'], conv_param_5['pad']))\n","        self.layers.append(layers.Relu())\n","        self.layers.append(layers.Convolution(self.params['W6'], self.params['b6'],\n","                           conv_param_6['stride'], conv_param_6['pad']))\n","        self.layers.append(layers.Relu())\n","        self.layers.append(layers.Pooling(pool_h=2, pool_w=2, stride=2))\n","        self.layers.append(layers.Affine(self.params['W7'], self.params['b7']))\n","        self.layers.append(layers.Relu())\n","        self.layers.append(layers.Dropout(0.5))\n","        self.layers.append(layers.Affine(self.params['W8'], self.params['b8']))\n","        self.layers.append(layers.Dropout(0.5))\n","        \n","        self.last_layer = layers.SoftmaxWithLoss()\n","\n","    def predict(self, x, train_flg=False):\n","        for layer in self.layers:\n","            if isinstance(layer, layers.Dropout):\n","                x = layer.forward(x, train_flg)\n","            else:\n","                x = layer.forward(x)\n","        return x\n","\n","    def loss(self, x, d):\n","        y = self.predict(x, train_flg=True)\n","        return self.last_layer.forward(y, d)\n","\n","    def accuracy(self, x, d, batch_size=100):\n","        if d.ndim != 1 : d = np.argmax(d, axis=1)\n","\n","        acc = 0.0\n","\n","        for i in range(int(x.shape[0] / batch_size)):\n","            tx = x[i*batch_size:(i+1)*batch_size]\n","            td = d[i*batch_size:(i+1)*batch_size]\n","            y = self.predict(tx, train_flg=False)\n","            y = np.argmax(y, axis=1)\n","            acc += np.sum(y == td)\n","\n","        return acc / x.shape[0]\n","\n","    def gradient(self, x, d):\n","        # forward\n","        self.loss(x, d)\n","\n","        # backward\n","        dout = 1\n","        dout = self.last_layer.backward(dout)\n","\n","        tmp_layers = self.layers.copy()\n","        tmp_layers.reverse()\n","        for layer in tmp_layers:\n","            dout = layer.backward(dout)\n","\n","        # 設定\n","        grads = {}\n","        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n","            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n","            grads['b' + str(i+1)] = self.layers[layer_idx].db\n","\n","        return grads"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1WMGCkV-odn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f699451c-2d43-47ca-ee25-2e0248b95f5b"},"source":["(x_train, d_train), (x_test, d_test) = load_mnist(flatten=False)\n","\n","# 処理に時間のかかる場合はデータを削減 \n","x_train, d_train = x_train[:5000], d_train[:5000]\n","x_test, d_test = x_test[:1000], d_test[:1000]\n","\n","print(\"データ読み込み完了\")\n","\n","network = DeepConvNet()  \n","optimizer = optimizer.Adam()\n","\n","iters_num = 1000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","\n","train_loss_list = []\n","accuracies_train = []\n","accuracies_test = []\n","\n","plot_interval=10\n","\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    d_batch = d_train[batch_mask]\n","    \n","    grad = network.gradient(x_batch, d_batch)\n","    optimizer.update(network.params, grad)\n","\n","    loss = network.loss(x_batch, d_batch)\n","    train_loss_list.append(loss)\n","\n","    if (i+1) % plot_interval == 0:\n","        accr_train = network.accuracy(x_train, d_train)\n","        accr_test = network.accuracy(x_test, d_test)\n","        accuracies_train.append(accr_train)\n","        accuracies_test.append(accr_test)\n","        \n","        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n","        print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))               \n","\n","lists = range(0, iters_num, plot_interval)\n","plt.plot(lists, accuracies_train, label=\"training set\")\n","plt.plot(lists, accuracies_test,  label=\"test set\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"accuracy\")\n","plt.xlabel(\"count\")\n","plt.ylabel(\"accuracy\")\n","plt.ylim(0, 1.0)\n","# グラフの表示\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["データ読み込み完了\n","(1024, 50)\n","Generation: 10. 正答率(トレーニング) = 0.2798\n","                : 10. 正答率(テスト) = 0.25\n","Generation: 20. 正答率(トレーニング) = 0.5994\n","                : 20. 正答率(テスト) = 0.591\n","Generation: 30. 正答率(トレーニング) = 0.6454\n","                : 30. 正答率(テスト) = 0.608\n","Generation: 40. 正答率(トレーニング) = 0.6686\n","                : 40. 正答率(テスト) = 0.645\n","Generation: 50. 正答率(トレーニング) = 0.7388\n","                : 50. 正答率(テスト) = 0.707\n","Generation: 60. 正答率(トレーニング) = 0.819\n","                : 60. 正答率(テスト) = 0.783\n","Generation: 70. 正答率(トレーニング) = 0.8442\n","                : 70. 正答率(テスト) = 0.813\n","Generation: 80. 正答率(トレーニング) = 0.8686\n","                : 80. 正答率(テスト) = 0.838\n","Generation: 90. 正答率(トレーニング) = 0.868\n","                : 90. 正答率(テスト) = 0.834\n","Generation: 100. 正答率(トレーニング) = 0.8872\n","                : 100. 正答率(テスト) = 0.875\n","Generation: 110. 正答率(トレーニング) = 0.9148\n","                : 110. 正答率(テスト) = 0.9\n","Generation: 120. 正答率(トレーニング) = 0.9238\n","                : 120. 正答率(テスト) = 0.911\n"]}]}]}